[{"name":"Home","description":"This is the documentation for MonkAI","path":"/home","text":"","wordCount":0,"type":"TOC"},{"name":"Whats new ?","description":"recent announcements, news, latest and greatest","path":"/home/whatsNew","text":"Latest Updates\n\n06-02-2020 -- Checkout the GSoC page for idea list.\n","wordCount":10,"type":"Content"},{"name":"Coding Standards","description":"","path":"/home/codingstandards","text":"Coming Soon!","wordCount":2,"type":"Content"},{"name":"Contribution Guidelines","description":"","path":"/home/contrib","text":"Coming Soon!\n","wordCount":2,"type":"Content"},{"name":"Image Classification","description":"Documentation for Image Classification algorithms","path":"/home/classification","text":"","wordCount":0,"type":"TOC"},{"name":"Tutorials","description":"Blog Post, Jupyter Notebook, Reference Links.","path":"/home/classification/tutorials","text":"Blog Posts\n\nApparel Object Classification\nCheckout MONKAI basic functions. Test our API reference for Pytorch, Keras and Mxnet.Use Densenets to build a Apparel Classifier\n\nIndoor Scene Classification\nUse Transfer Learning with MonkAI low code syntax for faster workaround. Create an image classifier for RealEstate ecommerce imagery.\n\nPlant Disease Classification\nAutomate Plant Disease Detection for early prevention of plant diseases.Explore quick Hyper-Parameter finding to analyse multiple hyper-parameters before proceeding with the actual experiment.\n\nSign Language Classification\nBuild an American Sign Language classifier and automate the process of video sign language translation.\n\nFood Classification\nBuild a Food Classification application using 3 levels of Food Classification models : \"Food vs Non Food\", \"11 super categories\", \"101 dishes\".\n\nJupyter Notebooks\n\nReference links\n","wordCount":106,"type":"Content"},{"name":"Features","description":"Key Features within MonkAI","path":"/home/classification/pipelines","text":"","wordCount":0,"type":"TOC"},{"name":"Resume Training","description":"temp","path":"/home/classification/pipelines/resume","text":"Documentation\n\nFunctional reference for Object Detection blocks","wordCount":6,"type":"Content"},{"name":"Copy Experiment","description":"temp","path":"/home/classification/pipelines/copy","text":"Documentation\n\nFunctional reference for Object Detection blocks","wordCount":6,"type":"Content"},{"name":"Modules","description":"Implementation blocks for Image Classification","path":"/home/classification/modules","text":"Hello","wordCount":1,"type":"Content"},{"name":"Object Detection","description":"Low-code Object Detection pipelines","path":"/home/detection","text":"","wordCount":0,"type":"TOC"},{"name":"Tutorials","description":"Ready to deploy use cases of Object Detection","path":"/home/detection/tutorials","text":"Blog Posts\n\nLogo Detection in Videos\nIntroduction to MonkAI Object Detection workflows. Create a custom object detector using MXRCNN on Open Logo Detection Challenge Dataset.\n\nJupyter Notebooks\n\nGluonCV-Finetune Examples\n\nComplete Examples\n\nBuilding a Hard Hat Detector\nBuilding a Weapon Detector\n\nTraining Examples\nTrain a Gluon ssd-300-vgg16-atrous-coco detector\nTrain a Gluon ssd-512-mobilenet1.0-coco detector\nTrain a Gluon ssd-512-mobilenet1.0-voc detector\nTrain a Gluon ssd-512-resnet50_v1-coco detector\nTrain a Gluon ssd-512-resnet50_v1-voc detector\nTrain a Gluon ssd-512-vgg16-atrous-coco detector\nTrain a Gluon ssd-512-vgg16-atrous-voc detector\nTrain a Gluon yolov3-darknet53-coco detector\nTrain a Gluon yolov3-darknet53-voc detector\nTrain a Gluon yolov3-mobilenet1.0-coco detector\nTrain a Gluon yolov3-mobilenet1.0-voc detector\n\nUtility Notebooks\n\nConvert Pascal VOC Annotations to Desired Format\n\nPytorch Finetune Examples\n\nTraining Examples\nTrain a Pytorch fasterRCNN-mobilenetv2 detector\n\nUtility Notebooks\nConvert Pascal VOC Annotations to Desired Format\n\nMXRCNN Examples\n\nComplete Examples\nBuilding a Logo Detector\nBuilding a Playing Card Detector\nBuilding a Weapon Detector\n\nTraining Examples\nTrain a Resnet50 detector\nTrain a Resnet101 detector\nTrain a VGG16 detector\n\nUtility Notebooks\nConvert Monk Annotations to COCO Format - Example 1\nConvert Monk Annotations to COCO Format - Example 2\nConvert VOC to COCO Format - via Monk Annotations\n\nEfficient Detection\n\nComplete Examples\nBuilding a Traffic Sign Detector with Multi-GPU support\nBuilding an Object Detector for low-light imagery\n\nTraining Examples\nTraining with Validation Data\nTraining without Validation Data\n\nUtility Notebooks\nConvert Monk Annotations to COCO format - Example 1\nConvert Monk Annotations to COCO format - Example 2\nConvert VOC to COCO format - via Monk Annotations\n\nPytorch Retinanet\n\nComplete Examples\nBuilding a Billboard Detector\nBuilding an Indoor Object Detector\nBuilding a Trash(Waste) Detector\n\nTraining Examples\nTraining Resnet18 with Validation Data\nTraining Resnet34 without Validation Data\n\nUtility Notebooks\nConvert Monk Annotations to COCO format - Example 1\nConvert Monk Annotations to COCO format - Example 2\nConvert VOC to COCO format - via Monk Annotations\n\nCornerNet Lite\n\nComplete Examples\nBuilding a Tiger Detector\n\nTraining Examples\nTraining CornerNet Saccade\nTraining CornerNet Squeeze\nTraining with Validation Data\nTraining without Validation Data\n\nUtility Notebooks\nConvert Monk Annotations to COCO format - Example 1\nConvert Monk Annotations to COCO format - Example 2\nConvert VOC to COCO format - via Monk Annotations\n\nYOLOv3\n\nComplete Examples\nBuilding a Wine Grape Detector\n\nTraining Examples\nTraining with Evolving Parameters\nTraining without Evolving Parameters\n\nUtility Notebooks\nConvert COCO to YOLO format\nConvert VOC to YOLO format\nConvert Monk to YOLO format\n","wordCount":305,"type":"Content"},{"name":"Pipelines","description":"Available pipelines for Object Detection","path":"/home/detection/pipelines","text":"","wordCount":0,"type":"TOC"},{"name":"GluonCV Finetune","description":"temp","path":"/home/detection/pipelines/gluonfinetune","text":"Project Details\nPipeline based on GluonCV Fintuning project - https://gluon-cv.mxnet.io/build/examples_detection/index.html\n\nInstallation\n\nSupports\nPython 3.6\nPython 3.7\n\ncd installation\n\nCheck the cuda version using the command\n\nnvcc -V\n\nSelect the right requirements file and run\n\ncat  | xargs -n 1 -L 1 pip install\n\nFor example for cuda 9.0\n\ncat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\ngtf.Dataset(rootdir, imgdir, annofile, batchsize=batch_size);\n\nLoad Model\n\ngtf.Model(modelname, usepretrained=pretrained, use_gpu=gpu);\n\nSet Hyper-parameter\n\ngtf.SetLearningRate(0.001);\n\nTrain\n\ngtf.Train(epochs, params_file);\n\nTODO\n\n[x] Add SSD support\n[x] Add YoloV3 support\n[ ] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[ ] Add Faster-RCNN support\n[x] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[x] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n\nExternal Contributors list\n\nhttps://github.com/THEFASHIONGEEK: Multi GPU feature","wordCount":163,"type":"Content"},{"name":"Pytorch Finetune","description":"temp","path":"/home/detection/pipelines/pytorchapi","text":"Project Details\nPipeline based on TorchVision Fintuning project - https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n\nInstallation\n\nSupports\nPython 3.6\nPython 3.7\n\ncd installation\n\nSelect the right requirements file and run\n\ncat  | xargs -n 1 -L 1 pip install\n\ncat requirements.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\ngtf.Dataset([trainrootdir, trainimgdir, trainannofile], batchsize=batchsize);\n\nLoad Model\n\ngtf.Model(modelname, usepretrained=pretrained, use_gpu=gpu);\n\nSet Hyper-parameter\n\ngtf.SetLearningRate(0.001);\n\nTrain\n\ngtf.Train(epochs, params_file);\n\nTODO\n\n[x] Add Faster-RCNN support\n[ ] Add YoloV3 support\n[ ] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[ ] Add support for Base Network Changes\n[x] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[ ] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature","wordCount":152,"type":"Content"},{"name":"MXRCNN","description":"temp","path":"/home/detection/pipelines/mxrcnn","text":"Project Details\nPipeline based on MX-RCNN project - https://github.com/ijkguo/mx-rcnn\n\nInstallation\n\nSupports\nPython 3.6\nCuda 9.0 (Other cuda version support is experimental)\n\ncd installation\n\nCheck the cuda version using the command\n\nnvcc -V\n\nSelect the right requirements file and run\n\ncat  | xargs -n 1 -L 1 pip install\n\nFor example for cuda 9.0\n\ncat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\nsetdatasetparams(rootdir=\"../sampledataset/\", coco_dir=\"kangaroo\", imageset=\"Images\");\n\nLoad Model\n\nsetmodelparams(model_name=\"vgg16\");\n\nSet Hyper-parameter\n\nsethyperparams(gpus=\"0\", lr=0.001, lrdecayepoch=\"1\", epochs=4, batch_size=1);\nsetoutputparams(loginterval=100, saveprefix=\"model_vgg16\");\n\nPreprocess dataset\n\n`setimgpreprocparams(imgshortside=600, imglong_side=1000,\n                       mean=(123.68, 116.779, 103.939), std=(1.0, 1.0, 1.0));`\n\nInitialize\n\ninitializerpnparams();\n\nInvoke data loader and network\n\nroidb = set_dataset();\nsym = set_network();\n\nTrain\n\ntrain(sym, roidb);\n\nTODO\n\n[x] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[x] Add Faster-RCNN support\n[ ] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[x] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n\nExternal Contributors list\n\nhttps://github.com/THEFASHIONGEEK: Multi GPU feature","wordCount":178,"type":"Content"},{"name":"Efficient Detection","description":"temp","path":"/home/detection/pipelines/efficientdet","text":"Project Details\nPipeline based on EfficientDet project - https://github.com/signatrix/efficientdet\n\nInstallation\n\nSupports\nPython 3.6\nCuda 9.0 (Other cuda version support is experimental)\n\ncd installation\n\ncat requirements.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\ngtf.TrainDataset(rootdir=\"../sampledataset\", cocodir=\"kangaroo\", imgdir=\"images\", setdir=\"Train\", batchsize=8, imagesize=512, use_gpu=True)\n\nLoad Model\n\ngtf.Model();\n\nSet Hyper Parameters\n\ngtf.SetHyperparams(lr=0.0001, valinterval=1, esmindelta=0.0, es_patience=0)\n\nTrain\n\ngtf.Train(numepochs=2, modeloutput_dir=\"trained/\");\n\nTODO\n\n[x] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[x] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[x] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n\nExternal Contributors list\n\nhttps://github.com/THEFASHIONGEEK: Multi GPU feature","wordCount":137,"type":"Content"},{"name":"RetinaNet-Pytorch","description":"temp","path":"/home/detection/pipelines/retinanet","text":"Pipelines## Project Details\nPipeline based on EfficientDet project - https://github.com/yhenon/pytorch-retinanet\n\nInstallation\n\nSupports\nPython 3.6\nCuda 9.0 (Other cuda version support is experimental)\n\ncd installation\n\ncat requirements.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\ngtf.TrainDataset(rootdir=\"../sampledataset\", cocodir=\"kangaroo\", imgdir=\"images\", setdir=\"Train\", batchsize=8, imagesize=512, use_gpu=True)\n\nLoad Model\n\ngtf.Model(model_name=\"resnet18\");\n\nSet Hyper Parameters\n\ngtf.SetHyperparams(lr=0.0001, valinterval=1, esmindelta=0.0, es_patience=0)\n\nTrain\n\ngtf.Train(numepochs=2, outputmodel_name=\"trained.pt\");\n\nTODO\n\n[x] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[x] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[x] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n\nExternal Contributors list\n\nhttps://github.com/THEFASHIONGEEK: Multi GPU feature","wordCount":138,"type":"Content"},{"name":"CornerNet-Lite","description":"temp","path":"/home/detection/pipelines/cornernet","text":"","wordCount":0,"type":"Content"},{"name":"YOLOv3","description":"temp","path":"/home/detection/pipelines/yolov3","text":"Project Details\nPipeline based on YoloV3 project - https://github.com/ultralytics/yolov3\n\nInstallation\n\nSupports\nPython 3.6\nCuda 9.0, 10.0 (Other cuda version support is experimental)\n\ncd installation\n\ncat requirements.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\n Load Dataset\n\n gtf.settraindataset(imgdir, labeldir, classlistfile, batch_size=2)\n\n Load Model\n\n gtf.setmodel(modelname=\"yolov3\");\n\n Set Hyper Params\n\n gtf.sethyperparams(optimizer=\"sgd\", lr=0.00579, multiscale=False, evolve=True, num_generations=2);\n\n  Train\n\n  gtf.Train(num_epochs=2);\n\nTODO\n\n[ ] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[x] Test on Kaggle and Colab\n[x] Add validation feature & data pipeline\n[ ] Resolve Error with original cornernet model\n[x] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[ ] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n","wordCount":144,"type":"Content"},{"name":"Modules","description":"Implementation blocks for Object Detection","path":"/home/detection/modules","text":"Hello","wordCount":1,"type":"Content"},{"name":"Custom Network Creator","description":"Documentation for Custom Neural Network Creator","path":"/home/custom","text":"","wordCount":0,"type":"TOC"},{"name":"Process Introduction","description":"how to read the process documentation","path":"/home/custom/introduction","text":"\nIntroduction\n\nTBD","wordCount":1,"type":"Content"},{"name":"New Pages HowTo","description":"how to create new Pages on the playbook","path":"/home/custom/newPagesHowto","text":"","wordCount":0,"type":"Content"},{"name":"MonkAI Studio","description":"Documentation for MonkAI Studio","path":"/home/studio","text":"","wordCount":0,"type":"TOC"},{"name":"Process Introduction","description":"how to read the process documentation","path":"/home/studio/introduction","text":"\nIntroduction\n\nTBD","wordCount":1,"type":"Content"},{"name":"New Pages HowTo","description":"how to create new Pages on the playbook","path":"/home/studio/newPagesHowto","text":"","wordCount":0,"type":"Content"},{"name":"GSoC 2020","description":"Information, Ideas List, Projects, Mentors, Requirements and more.","path":"/home/gsoc2020","text":"","wordCount":0,"type":"TOC"},{"name":"Ideas List","description":"List of Project Ideas","path":"/home/gsoc2020/ideaslist","text":"Coming Soon!","wordCount":2,"type":"Content"},{"name":"Coding Standards","description":"","path":"/home/gsoc2020/codingstandards","text":"Coming Soon!","wordCount":2,"type":"Content"},{"name":"Contribution Guidelines","description":"","path":"/home/gsoc2020/contrib","text":"Coming Soon!\n","wordCount":2,"type":"Content"}]