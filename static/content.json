[{"name":"Home","description":"This is the documentation for MonkAI","path":"/home","text":"","wordCount":0,"type":"TOC"},{"name":"Whats new ?","description":"recent announcements, news, latest and greatest","path":"/home/whatsNew","text":"Latest Updates\n\n06-02-2020 -- Checkout the GSoC page for idea list.\n","wordCount":10,"type":"Content"},{"name":"Coding Standards","description":"","path":"/home/codingstandards","text":"Coming Soon!","wordCount":2,"type":"Content"},{"name":"Contribution Guidelines","description":"","path":"/home/contrib","text":"Coming Soon!\n","wordCount":2,"type":"Content"},{"name":"Image Classification","description":"Documentation for Image Classification algorithms","path":"/home/classification","text":"","wordCount":0,"type":"TOC"},{"name":"Tutorials","description":"Blog Post, Jupyter Notebook, Reference Links.","path":"/home/classification/tutorials","text":"Blog Posts\n\nApparel Object Classification\nCheckout MONKAI basic functions. Test our API reference for Pytorch, Keras and Mxnet.Use Densenets to build a Apparel Classifier\n\nIndoor Scene Classification\nUse Transfer Learning with MonkAI low code syntax for faster workaround. Create an image classifier for RealEstate ecommerce imagery.\n\nPlant Disease Classification\nAutomate Plant Disease Detection for early prevention of plant diseases.Explore quick Hyper-Parameter finding to analyse multiple hyper-parameters before proceeding with the actual experiment.\n\nSign Language Classification\nBuild an American Sign Language classifier and automate the process of video sign language translation.\n\nFood Classification\nBuild a Food Classification application using 3 levels of Food Classification models : \"Food vs Non Food\", \"11 super categories\", \"101 dishes\".\n\nJupyter Notebooks\n\nReference links\n","wordCount":106,"type":"Content"},{"name":"Features","description":"Key Features within MonkAI","path":"/home/classification/pipelines","text":"","wordCount":0,"type":"TOC"},{"name":"Resume Training","description":"temp","path":"/home/classification/pipelines/resume","text":"Documentation\n\nFunctional reference for Object Detection blocks","wordCount":6,"type":"Content"},{"name":"Copy Experiment","description":"temp","path":"/home/classification/pipelines/copy","text":"Documentation\n\nFunctional reference for Object Detection blocks","wordCount":6,"type":"Content"},{"name":"Modules","description":"Implementation blocks for Image Classification","path":"/home/classification/modules","text":"Hello","wordCount":1,"type":"Content"},{"name":"Object Detection","description":"Low-code Object Detection pipelines","path":"/home/detection","text":"","wordCount":0,"type":"TOC"},{"name":"Tutorials","description":"Ready to deploy use cases of Object Detection","path":"/home/detection/tutorials","text":"Blog Posts\n\nLogo Detection in Videos\nIntroduction to MonkAI Object Detection workflows. Create a custom object detector using MXRCNN on Open Logo Detection Challenge Dataset.\n\nJupyter Notebooks\n\nGluonCV-Finetune Examples\n\nComplete Examples\n\nBuilding a Hard Hat Detector\nBuilding a Weapon Detector\n\nTraining Examples\nTrain a Gluon ssd-300-vgg16-atrous-coco detector\nTrain a Gluon ssd-512-mobilenet1.0-coco detector\nTrain a Gluon ssd-512-mobilenet1.0-voc detector\nTrain a Gluon ssd-512-resnet50_v1-coco detector\nTrain a Gluon ssd-512-resnet50_v1-voc detector\nTrain a Gluon ssd-512-vgg16-atrous-coco detector\nTrain a Gluon ssd-512-vgg16-atrous-voc detector\nTrain a Gluon yolov3-darknet53-coco detector\nTrain a Gluon yolov3-darknet53-voc detector\nTrain a Gluon yolov3-mobilenet1.0-coco detector\nTrain a Gluon yolov3-mobilenet1.0-voc detector\n\nUtility Notebooks\n\nConvert Pascal VOC Annotations to Desired Format\n\nPytorch Finetune Examples\n\nTraining Examples\nTrain a Pytorch fasterRCNN-mobilenetv2 detector\n\nUtility Notebooks\nConvert Pascal VOC Annotations to Desired Format\n\nMXRCNN Examples\n\nComplete Examples\nBuilding a Logo Detector\nBuilding a Playing Card Detector\nBuilding a Weapon Detector\n\nTraining Examples\nTrain a Resnet50 detector\nTrain a Resnet101 detector\nTrain a VGG16 detector\n\nUtility Notebooks\nConvert Monk Annotations to COCO Format - Example 1\nConvert Monk Annotations to COCO Format - Example 2\nConvert VOC to COCO Format - via Monk Annotations\n\nEfficient Detection\n\nComplete Examples\nBuilding a Traffic Sign Detector with Multi-GPU support\nBuilding an Object Detector for low-light imagery\n\nTraining Examples\nTraining with Validation Data\nTraining without Validation Data\n\nUtility Notebooks\nConvert Monk Annotations to COCO format - Example 1\nConvert Monk Annotations to COCO format - Example 2\nConvert VOC to COCO format - via Monk Annotations\n\nPytorch Retinanet\n\nComplete Examples\nBuilding a Billboard Detector\nBuilding an Indoor Object Detector\nBuilding a Trash(Waste) Detector\n\nTraining Examples\nTraining Resnet18 with Validation Data\nTraining Resnet34 without Validation Data\n\nUtility Notebooks\nConvert Monk Annotations to COCO format - Example 1\nConvert Monk Annotations to COCO format - Example 2\nConvert VOC to COCO format - via Monk Annotations\n\nCornerNet Lite\n\nComplete Examples\nBuilding a Tiger Detector\n\nTraining Examples\nTraining CornerNet Saccade\nTraining CornerNet Squeeze\nTraining with Validation Data\nTraining without Validation Data\n\nUtility Notebooks\nConvert Monk Annotations to COCO format - Example 1\nConvert Monk Annotations to COCO format - Example 2\nConvert VOC to COCO format - via Monk Annotations\n\nYOLOv3\n\nComplete Examples\nBuilding a Wine Grape Detector\n\nTraining Examples\nTraining with Evolving Parameters\nTraining without Evolving Parameters\n\nUtility Notebooks\nConvert COCO to YOLO format\nConvert VOC to YOLO format\nConvert Monk to YOLO format\n","wordCount":305,"type":"Content"},{"name":"Pipelines","description":"Available pipelines for Object Detection","path":"/home/detection/pipelines","text":"","wordCount":0,"type":"TOC"},{"name":"GluonCV Finetune","description":"temp","path":"/home/detection/pipelines/gluonfinetune","text":"Project Details\nPipeline based on GluonCV Fintuning project - https://gluon-cv.mxnet.io/build/examples_detection/index.html\n\nInstallation\n\nSupports\nPython 3.6\nPython 3.7\n\ncd installation\n\nCheck the cuda version using the command\n\nnvcc -V\n\nSelect the right requirements file and run\n\ncat  | xargs -n 1 -L 1 pip install\n\nFor example for cuda 9.0\n\ncat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\ngtf.Dataset(rootdir, imgdir, annofile, batchsize=batch_size);\n\nLoad Model\n\ngtf.Model(modelname, usepretrained=pretrained, use_gpu=gpu);\n\nSet Hyper-parameter\n\ngtf.SetLearningRate(0.001);\n\nTrain\n\ngtf.Train(epochs, params_file);\n\nTODO\n\n[x] Add SSD support\n[x] Add YoloV3 support\n[ ] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[ ] Add Faster-RCNN support\n[x] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[x] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n\nExternal Contributors list\n\nhttps://github.com/THEFASHIONGEEK: Multi GPU feature","wordCount":163,"type":"Content"},{"name":"Pytorch Finetune","description":"temp","path":"/home/detection/pipelines/pytorchapi","text":"Project Details\nPipeline based on TorchVision Fintuning project - https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n\nInstallation\n\nSupports\nPython 3.6\nPython 3.7\n\ncd installation\n\nSelect the right requirements file and run\n\ncat  | xargs -n 1 -L 1 pip install\n\ncat requirements.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\ngtf.Dataset([trainrootdir, trainimgdir, trainannofile], batchsize=batchsize);\n\nLoad Model\n\ngtf.Model(modelname, usepretrained=pretrained, use_gpu=gpu);\n\nSet Hyper-parameter\n\ngtf.SetLearningRate(0.001);\n\nTrain\n\ngtf.Train(epochs, params_file);\n\nTODO\n\n[x] Add Faster-RCNN support\n[ ] Add YoloV3 support\n[ ] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[ ] Add support for Base Network Changes\n[x] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[ ] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature","wordCount":152,"type":"Content"},{"name":"MXRCNN","description":"temp","path":"/home/detection/pipelines/mxrcnn","text":"Project Details\nPipeline based on MX-RCNN project - https://github.com/ijkguo/mx-rcnn\n\nInstallation\n\nSupports\nPython 3.6\nCuda 9.0 (Other cuda version support is experimental)\n\ncd installation\n\nCheck the cuda version using the command\n\nnvcc -V\n\nSelect the right requirements file and run\n\ncat  | xargs -n 1 -L 1 pip install\n\nFor example for cuda 9.0\n\ncat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\nsetdatasetparams(rootdir=\"../sampledataset/\", coco_dir=\"kangaroo\", imageset=\"Images\");\n\nLoad Model\n\nsetmodelparams(model_name=\"vgg16\");\n\nSet Hyper-parameter\n\nsethyperparams(gpus=\"0\", lr=0.001, lrdecayepoch=\"1\", epochs=4, batch_size=1);\nsetoutputparams(loginterval=100, saveprefix=\"model_vgg16\");\n\nPreprocess dataset\n\n`setimgpreprocparams(imgshortside=600, imglong_side=1000,\n                       mean=(123.68, 116.779, 103.939), std=(1.0, 1.0, 1.0));`\n\nInitialize\n\ninitializerpnparams();\n\nInvoke data loader and network\n\nroidb = set_dataset();\nsym = set_network();\n\nTrain\n\ntrain(sym, roidb);\n\nTODO\n\n[x] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[x] Add Faster-RCNN support\n[ ] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[x] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n\nExternal Contributors list\n\nhttps://github.com/THEFASHIONGEEK: Multi GPU feature","wordCount":178,"type":"Content"},{"name":"Efficient Detection","description":"temp","path":"/home/detection/pipelines/efficientdet","text":"Project Details\nPipeline based on EfficientDet project - https://github.com/signatrix/efficientdet\n\nInstallation\n\nSupports\nPython 3.6\nCuda 9.0 (Other cuda version support is experimental)\n\ncd installation\n\ncat requirements.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\ngtf.TrainDataset(rootdir=\"../sampledataset\", cocodir=\"kangaroo\", imgdir=\"images\", setdir=\"Train\", batchsize=8, imagesize=512, use_gpu=True)\n\nLoad Model\n\ngtf.Model();\n\nSet Hyper Parameters\n\ngtf.SetHyperparams(lr=0.0001, valinterval=1, esmindelta=0.0, es_patience=0)\n\nTrain\n\ngtf.Train(numepochs=2, modeloutput_dir=\"trained/\");\n\nTODO\n\n[x] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[x] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[x] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n\nExternal Contributors list\n\nhttps://github.com/THEFASHIONGEEK: Multi GPU feature","wordCount":137,"type":"Content"},{"name":"RetinaNet-Pytorch","description":"temp","path":"/home/detection/pipelines/retinanet","text":"Pipelines## Project Details\nPipeline based on EfficientDet project - https://github.com/yhenon/pytorch-retinanet\n\nInstallation\n\nSupports\nPython 3.6\nCuda 9.0 (Other cuda version support is experimental)\n\ncd installation\n\ncat requirements.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\nLoad Dataset\n\ngtf.TrainDataset(rootdir=\"../sampledataset\", cocodir=\"kangaroo\", imgdir=\"images\", setdir=\"Train\", batchsize=8, imagesize=512, use_gpu=True)\n\nLoad Model\n\ngtf.Model(model_name=\"resnet18\");\n\nSet Hyper Parameters\n\ngtf.SetHyperparams(lr=0.0001, valinterval=1, esmindelta=0.0, es_patience=0)\n\nTrain\n\ngtf.Train(numepochs=2, outputmodel_name=\"trained.pt\");\n\nTODO\n\n[x] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[x] Test on Kaggle and Colab\n[ ] Add validation feature & data pipeline\n[ ] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[x] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n\nExternal Contributors list\n\nhttps://github.com/THEFASHIONGEEK: Multi GPU feature","wordCount":138,"type":"Content"},{"name":"CornerNet-Lite","description":"temp","path":"/home/detection/pipelines/cornernet","text":"","wordCount":0,"type":"Content"},{"name":"YOLOv3","description":"temp","path":"/home/detection/pipelines/yolov3","text":"Project Details\nPipeline based on YoloV3 project - https://github.com/ultralytics/yolov3\n\nInstallation\n\nSupports\nPython 3.6\nCuda 9.0, 10.0 (Other cuda version support is experimental)\n\ncd installation\n\ncat requirements.txt | xargs -n 1 -L 1 pip install\n\nPipeline\n\n Load Dataset\n\n gtf.settraindataset(imgdir, labeldir, classlistfile, batch_size=2)\n\n Load Model\n\n gtf.setmodel(modelname=\"yolov3\");\n\n Set Hyper Params\n\n gtf.sethyperparams(optimizer=\"sgd\", lr=0.00579, multiscale=False, evolve=True, num_generations=2);\n\n  Train\n\n  gtf.Train(num_epochs=2);\n\nTODO\n\n[ ] Add support for Coco-Type Annotated Datasets\n[x] Add support for VOC-Type Annotated Dataset\n[x] Test on Kaggle and Colab\n[x] Add validation feature & data pipeline\n[ ] Resolve Error with original cornernet model\n[x] Add Optimizer selection feature\n[ ] Enable Learning-Rate Scheduler Support\n[ ] Enable Layer Freezing\n[ ] Set Verbosity Levels\n[ ] Add Project management and version control support (Similar to Monk Classification)\n[ ] Add Graph Visualization Support\n[ ] Enable batch proessing at inference\n[ ] Add feature for top-k output visualization\n[ ] Add Multi-GPU training\n[ ] Auto correct missing or corrupt images - Currently skips them\n[ ] Add Experimental Data Analysis Feature\n","wordCount":144,"type":"Content"},{"name":"Modules","description":"Implementation blocks for Object Detection","path":"/home/detection/modules","text":"Hello","wordCount":1,"type":"Content"},{"name":"Custom Network Creator","description":"Documentation for Custom Neural Network Creator","path":"/home/custom","text":"","wordCount":0,"type":"Content"},{"name":"MonkAI Studio","description":"Documentation for MonkAI Studio","path":"/home/studio","text":"","wordCount":0,"type":"Content"},{"name":"GSoC 2020","description":"Information, Ideas List, Projects, Mentors, Requirements and more.","path":"/home/gsoc2020","text":"","wordCount":0,"type":"TOC"},{"name":"Getting Started","description":"","path":"/home/gsoc2020/getstarted","text":"What is MonkAI\n\nMonkAI is a syntax invariant wrapper on popular Deep Learning frameworks like Pytorch, Keras, Mxnet. The goals are to reduce cognitive loads for novice programmers along with a host of features of value to a domain expert.\n\nGoogle Summer of Code\n\nGoogle Summer of Code (GSoC) is a global program that offers post-secondary students an opportunity to be paid for contributing to an open source project over a three month period.\n\nWe're hoping to participate in GSoC 2020! (Google announces their selections on Feb 20, 2020. Stay tuned for updates!)\n\nImportant Links :\nIdeas Page\nHow to apply\nGet in Touch\n\nHow to get started\n\nBeing in its early days, MonkAI requires the support of Computer Vision and Deep Learning enthusiasts to guide and participate in the design and development of the library. Currently the following features are available in MonkAI:\n\nImage Classification using Transfer Learning\nObject Detection workflows with a variety of Deep Neural architectures\nCustom Neural Network designer\nMonkAI Studio - for a GUI based classification and detection workflows\n\nAny open source experience will help you prepare for GSoC, so don't worry too much about what project you try first and don't be afraid to change your mind!\n\nA few steps before you should apply :\n\nSetup your own development environment and test out the library and tools\nStart communicating with the developers and mentors\nTry to fix any open bugs\nHunt and report bugs\nProvide help with documentation\nHelp others!\n","wordCount":224,"type":"Content"},{"name":"Ideas List","description":"List of Project Ideas","path":"/home/gsoc2020/ideaslist","text":"Ideas List\n\nIntegrating Tensorflow 2.0 support for Transfer Learning based Image Classification\n\tSource Code :\n\tMonk Image Classification\n\n\tProject Description :\n\tAdd a low-code wrapper over tensorflow-2.0 as per monk repository's coding standards and backend formats. Goal is to replicate all the modules present in monk's backends (pytorch, keras and mxnet) and create a new one to enable transfer learning and general image classification using tensorflow2.0 backend.\n\n\tObjectives :\n\tPull Monk repository and test in a local setup\n\tRun all the examples present in each backend.\n\tGo through Documentation and understand the syntax, implementation modules and pipelines.\n\tUnderstand folder and directory sturcture for codes for keras backend.\n\tUnderstand different modes of operation in available backends\n\t    quick mode\n\t    update mode\n\t    expert mode\n\t    switch mode\n\tUnderstand how metrics are being saved and used in comparison mode\n\tUnderstand working of hyper-parameter finders\n\tUnderstand how custom network builder works in different backends.\n\tCreate wrappers overs\n\t    pretrained model loaders\n\t    data loaders for single label and multi label classification\n\t    Nural network layers, activation functions, loss functions, optimizers and learning rate schedulers\n\t    data-transformation functions\n\tReplicate modes as present in rest of the backends\n\t    quick mode\n\t    update mode\n\t    expert mode\n\t    switch mode\n\tCreate hyper-parameter fiinder module with tf-2.0 backend\n\tCreate custom network builder\n\tWrite examples similat to the ones existing with the other backends in monk repository\n\n\tMentors : Abhishek Kumar Annamraju\n\n\tDifficulty Level : High\n\nCreating Object Detection workflows across different imaging modalities\n\tSource Code :\n\tMonk Object Detection\n\n\tProject Description :\n\tExplore state of the art Object Detection research implementations for :\n\t1) Thermal Imagery\n\t2) Multispectral Satellite Imagery\n\t3) Biomedical Imagery\n\t4) Document Imagery\n\t5) Face Recognition\n\n\tand create a high level wrapper using Monk's syntax.\n\n\tObjectives :\n\tPull Monk Object Detection repository and test in a local setup\n\tGo through Documentation and understand the syntax, implementation modules and pipelines.\n\tExplore state of the art algorithms, datasets and applications on different imaging modalities\n\tCreate 10 workflows ( 2 for each imaging modality )\n\tBuild unit tests for setting up Monk locally\n\tCreate blog posts for every workflow\n\tPrepare documentation about the implementation\n\n\tMentors : Akash Deep Singh\n\n\tDifficulty Level : Medium\n\nCreating Monk-Studio web application\n\nSource Code :\nMonk Object Detection\n\nObjectives :\n\nMentors : Akash Deep Singh\n\nDifficulty Level : Medium\n\nCreating a Custom Network Builder web application\n\nSource Code :\nMonk Image Classification\n\nProject Description :\n\nObjectives :\n\nMentors : Abhishek Kumar Annamraju\n\nDifficulty Level : High\n\nOne-Click Model deploy to Cloud\n\nSource Code :\nMonk Image Classification\n\nProject Description :\n\nObjectives :\n\nMentors : Abhishek Kumar Annamraju\n\nDifficulty Level : High\n","wordCount":367,"type":"Content"},{"name":"How to Apply","description":"Information for Applicants","path":"/home/gsoc2020/howtoapply","text":"Short application checklist:\n\nRead the links and instructions -- All of it! we've tried to give you all the information you need to be an awesome student applicant.\n\nChoose a project (check the list here).\n\nPrepare a patch for that project. We expect students to fix a bug and have made a pull request (or equivalent).\n\nYour code doesn't have to be accepted and merged, but it does have to be visible to the public and it does have to be your own work (mentor help is ok, code you didn't write is not).\n\nWrite your application (with help from your mentors!)\n\nAll applications must go through Google's application system; we can't accept any application unless it is submitted there.\n\nUse a descriptive title and include your project name in Google's system.\nMake it easy for your mentors to give you feedback using online document collaboration tools.\nSubmit your application to Google before the deadline.\n\nHow should your application look!\n\nAn ideal application will contain 5 things:\nA descriptive title including the name of the project you want to work on\nInformation about you, including contact information\nLink to a code contribution you have made to the organization\nInformation about your proposed plan for the project. This should be fairly detailed and must include a timeline\nInformation about other commitments that might affect your ability to work during the GSoC period. (exams, classes, holidays, other jobs, weddings, etc.)\n","wordCount":222,"type":"Content"},{"name":"Get in Touch","description":"","path":"/home/gsoc2020/getintouch","text":"Getting in touch\n\nThe admins & mentors for GSoC 2020 are :\n\nAbhishek Kumar Annamraju\n  Linkedin\n  Facebook\n  Email : abhishek@tessellateimaging.com\n\nAkash Deep Singh\n  Linkedin\n  Facebook\n  Email : akash@tessellateimaging.com\n\nTo join our community on slack visit HERE\n\nTo signup for our mailing list visit MonkAI\n","wordCount":38,"type":"Content"},{"name":"Coding Standards","description":"","path":"/home/gsoc2020/codingstandards","text":"Coming Soon!","wordCount":2,"type":"Content"},{"name":"Contribution Guidelines","description":"","path":"/home/gsoc2020/contrib","text":"Coming Soon!\n","wordCount":2,"type":"Content"}]